================ HW / GPU INFO ================
Date: Wed Dec 31 09:45:04 AEDT 2025
Host: k172
Job:  7316629[11].<CLUSTER_DOMAIN>  ArrayIndex: 11
GPU 0: NVIDIA L40S (UUID: GPU-34b6f0b5-b652-519d-9af6-3dfd2449e70c)
0, NVIDIA L40S, GPU-34b6f0b5-b652-519d-9af6-3dfd2449e70c, 580.95.05, 46068 MiB
===============================================
2025-12-31 09:45:13,969 [INFO] [chunk 11/15] Loading tokenizer and model: microsoft/Phi-3-mini-4k-instruct
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.36s/it]
2025-12-31 09:45:21,043 [INFO] [chunk 11/15] Model loaded on cuda
2025-12-31 09:45:21,043 [INFO] [chunk 11/15] Context limit C = 4096, max_new_tokens B = 16384
2025-12-31 09:45:21,048 [INFO] [chunk 11/15] Evaluating [repeat_style] prompt: code_v3
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
This is a friendly reminder - the current text generation call has exceeded the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.
2025-12-31 10:05:50,727 [INFO] [chunk 11/15] Evaluating [repeat_style] prompt: code_v4
2025-12-31 10:25:15,438 [INFO] [chunk 11/15] [repeat_style] Global Success@OGF>=1 across 68 runs (this chunk): 13.24%
2025-12-31 10:25:15,439 [INFO] [chunk 11/15] Evaluating [infinite_babble] prompt: infinite_babble_v23
2025-12-31 11:04:05,366 [INFO] [chunk 11/15] Evaluating [infinite_babble] prompt: infinite_babble_v24
2025-12-31 11:55:52,569 [INFO] [chunk 11/15] [infinite_babble] Global Success@OGF>=1 across 68 runs (this chunk): 36.76%
2025-12-31 11:55:52,570 [INFO] [chunk 11/15] Evaluating [random_short] prompt: random_077
2025-12-31 12:11:46,038 [INFO] [chunk 11/15] Evaluating [random_short] prompt: random_078
2025-12-31 12:24:01,739 [INFO] [chunk 11/15] Evaluating [random_short] prompt: random_079
2025-12-31 12:37:07,750 [INFO] [chunk 11/15] Evaluating [random_short] prompt: random_080
2025-12-31 12:48:26,657 [INFO] [chunk 11/15] Evaluating [random_short] prompt: random_081
2025-12-31 13:04:02,530 [INFO] [chunk 11/15] Evaluating [random_short] prompt: random_082
2025-12-31 13:11:53,098 [INFO] [chunk 11/15] Evaluating [random_short] prompt: random_083
2025-12-31 13:28:15,177 [INFO] [chunk 11/15] [random_short] Global Success@OGF>=1 across 238 runs (this chunk): 5.88%
2025-12-31 13:28:15,178 [INFO] [chunk 11/15] Loaded 100 Wizard-style prompts from wizardlm.jsonl
2025-12-31 13:28:15,179 [INFO] [chunk 11/15] Evaluating [wizard_instruct] prompt: wizard_00077
2025-12-31 13:33:05,733 [INFO] [chunk 11/15] Evaluating [wizard_instruct] prompt: wizard_00078
2025-12-31 13:43:48,743 [INFO] [chunk 11/15] Evaluating [wizard_instruct] prompt: wizard_00079
2025-12-31 13:47:01,873 [INFO] [chunk 11/15] Evaluating [wizard_instruct] prompt: wizard_00080
2025-12-31 13:50:45,046 [INFO] [chunk 11/15] Evaluating [wizard_instruct] prompt: wizard_00081
2025-12-31 14:03:32,709 [INFO] [chunk 11/15] Evaluating [wizard_instruct] prompt: wizard_00082
2025-12-31 14:08:12,225 [INFO] [chunk 11/15] Evaluating [wizard_instruct] prompt: wizard_00083
2025-12-31 14:14:04,488 [INFO] [chunk 11/15] [wizard_instruct] Global Success@OGF>=1 across 238 runs (this chunk): 1.68%

================================================================================
                     Resource Usage on 31/12/2025 14:14:08                      

Job Id: 7316629[11] 
Queue: ADFA
Walltime: 04:29:01  (requested 12:00:00)
Job execution was successful. Exit Status 0. 

--------------------------------------------------------------------------------
|              |             GPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node  GPU ID | Requested   Used   Efficiency | Available   Used              |
| k172    0    |     1       0.92       92%    | 46068 MiB   8.75G             |
--------------------------------------------------------------------------------
|Total         |     1       0.92      92.0%   |                               |
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
|              |             CPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node         | Requested   Used   Efficiency | Requested   Used   Efficiency |
| k172         |     4        1.0      25.0%   |  32.0gb    14.72gb    46.0%   |
--------------------------------------------------------------------------------
