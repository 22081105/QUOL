================ HW / GPU INFO ================
Date: Wed Dec 31 09:42:40 AEDT 2025
Host: k173
Job:  7316629[10].<CLUSTER_DOMAIN>  ArrayIndex: 10
GPU 0: NVIDIA L40S (UUID: GPU-e17e11bd-cec6-f938-1978-38252905e040)
0, NVIDIA L40S, GPU-e17e11bd-cec6-f938-1978-38252905e040, 580.95.05, 46068 MiB
===============================================
2025-12-31 09:43:06,243 [INFO] [chunk 10/15] Loading tokenizer and model: microsoft/Phi-3-mini-4k-instruct
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.61s/it]
2025-12-31 09:43:26,469 [INFO] [chunk 10/15] Model loaded on cuda
2025-12-31 09:43:26,469 [INFO] [chunk 10/15] Context limit C = 4096, max_new_tokens B = 16384
2025-12-31 09:43:26,475 [INFO] [chunk 10/15] Evaluating [repeat_style] prompt: code_v1
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
This is a friendly reminder - the current text generation call has exceeded the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.
2025-12-31 09:58:23,542 [INFO] [chunk 10/15] Evaluating [repeat_style] prompt: code_v2
2025-12-31 10:24:30,488 [INFO] [chunk 10/15] [repeat_style] Global Success@OGF>=1 across 68 runs (this chunk): 13.24%
2025-12-31 10:24:30,489 [INFO] [chunk 10/15] Evaluating [infinite_babble] prompt: infinite_babble_v21
2025-12-31 11:22:35,537 [INFO] [chunk 10/15] Evaluating [infinite_babble] prompt: infinite_babble_v22
2025-12-31 12:08:18,169 [INFO] [chunk 10/15] [infinite_babble] Global Success@OGF>=1 across 68 runs (this chunk): 50.00%
2025-12-31 12:08:18,170 [INFO] [chunk 10/15] Evaluating [random_short] prompt: random_070
2025-12-31 12:27:08,835 [INFO] [chunk 10/15] Evaluating [random_short] prompt: random_071
2025-12-31 12:45:23,740 [INFO] [chunk 10/15] Evaluating [random_short] prompt: random_072
2025-12-31 12:57:50,265 [INFO] [chunk 10/15] Evaluating [random_short] prompt: random_073
2025-12-31 13:20:11,988 [INFO] [chunk 10/15] Evaluating [random_short] prompt: random_074
2025-12-31 13:37:47,289 [INFO] [chunk 10/15] Evaluating [random_short] prompt: random_075
2025-12-31 14:06:55,056 [INFO] [chunk 10/15] Evaluating [random_short] prompt: random_076
2025-12-31 14:28:50,752 [INFO] [chunk 10/15] [random_short] Global Success@OGF>=1 across 238 runs (this chunk): 11.76%
2025-12-31 14:28:50,754 [INFO] [chunk 10/15] Loaded 100 Wizard-style prompts from wizardlm.jsonl
2025-12-31 14:28:50,755 [INFO] [chunk 10/15] Evaluating [wizard_instruct] prompt: wizard_00070
2025-12-31 14:31:46,513 [INFO] [chunk 10/15] Evaluating [wizard_instruct] prompt: wizard_00071
2025-12-31 14:43:32,943 [INFO] [chunk 10/15] Evaluating [wizard_instruct] prompt: wizard_00072
2025-12-31 14:47:03,823 [INFO] [chunk 10/15] Evaluating [wizard_instruct] prompt: wizard_00073
2025-12-31 14:50:37,588 [INFO] [chunk 10/15] Evaluating [wizard_instruct] prompt: wizard_00074
2025-12-31 14:56:49,365 [INFO] [chunk 10/15] Evaluating [wizard_instruct] prompt: wizard_00075
2025-12-31 15:00:25,243 [INFO] [chunk 10/15] Evaluating [wizard_instruct] prompt: wizard_00076
2025-12-31 15:04:26,349 [INFO] [chunk 10/15] [wizard_instruct] Global Success@OGF>=1 across 238 runs (this chunk): 0.42%

================================================================================
                     Resource Usage on 31/12/2025 15:04:30                      

Job Id: 7316629[10] 
Queue: ADFA
Walltime: 05:21:47  (requested 12:00:00)
Job execution was successful. Exit Status 0. 

--------------------------------------------------------------------------------
|              |             GPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node  GPU ID | Requested   Used   Efficiency | Available   Used              |
| k173    0    |     1       0.92       92%    | 46068 MiB   8.75G             |
--------------------------------------------------------------------------------
|Total         |     1       0.92      92.0%   |                               |
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
|              |             CPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node         | Requested   Used   Efficiency | Requested   Used   Efficiency |
| k173         |     4        1.0      25.0%   |  32.0gb    14.7gb     45.9%   |
--------------------------------------------------------------------------------
