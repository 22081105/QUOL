================ HW / GPU INFO ================
Date: Wed Dec 31 09:02:01 AEDT 2025
Host: k094
Job:  7316629[9].<CLUSTER_DOMAIN>  ArrayIndex: 9
GPU 0: NVIDIA L40S (UUID: GPU-521a81fc-da81-ca47-beeb-1055b1101011)
0, NVIDIA L40S, GPU-521a81fc-da81-ca47-beeb-1055b1101011, 580.95.05, 46068 MiB
===============================================
2025-12-31 09:02:09,057 [INFO] [chunk 9/15] Loading tokenizer and model: microsoft/Phi-3-mini-4k-instruct
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.43s/it]
2025-12-31 09:02:16,129 [INFO] [chunk 9/15] Model loaded on cuda
2025-12-31 09:02:16,129 [INFO] [chunk 9/15] Context limit C = 4096, max_new_tokens B = 16384
2025-12-31 09:02:16,134 [INFO] [chunk 9/15] Evaluating [repeat_style] prompt: longtext_v4
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
This is a friendly reminder - the current text generation call has exceeded the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.
2025-12-31 09:31:06,946 [INFO] [chunk 9/15] Evaluating [repeat_style] prompt: longtext_v5
2025-12-31 09:57:41,635 [INFO] [chunk 9/15] [repeat_style] Global Success@OGF>=1 across 68 runs (this chunk): 17.65%
2025-12-31 09:57:41,635 [INFO] [chunk 9/15] Evaluating [infinite_babble] prompt: infinite_babble_v19
2025-12-31 10:41:38,519 [INFO] [chunk 9/15] Evaluating [infinite_babble] prompt: infinite_babble_v20
2025-12-31 11:15:58,198 [INFO] [chunk 9/15] [infinite_babble] Global Success@OGF>=1 across 68 runs (this chunk): 33.82%
2025-12-31 11:15:58,200 [INFO] [chunk 9/15] Evaluating [random_short] prompt: random_063
2025-12-31 11:48:46,887 [INFO] [chunk 9/15] Evaluating [random_short] prompt: random_064
2025-12-31 12:21:14,655 [INFO] [chunk 9/15] Evaluating [random_short] prompt: random_065
2025-12-31 12:43:18,725 [INFO] [chunk 9/15] Evaluating [random_short] prompt: random_066
2025-12-31 12:59:03,321 [INFO] [chunk 9/15] Evaluating [random_short] prompt: random_067
2025-12-31 13:17:45,789 [INFO] [chunk 9/15] Evaluating [random_short] prompt: random_068
2025-12-31 13:41:07,364 [INFO] [chunk 9/15] Evaluating [random_short] prompt: random_069
2025-12-31 14:22:53,540 [INFO] [chunk 9/15] [random_short] Global Success@OGF>=1 across 238 runs (this chunk): 19.33%
2025-12-31 14:22:53,542 [INFO] [chunk 9/15] Loaded 100 Wizard-style prompts from wizardlm.jsonl
2025-12-31 14:22:53,543 [INFO] [chunk 9/15] Evaluating [wizard_instruct] prompt: wizard_00063
2025-12-31 14:44:40,639 [INFO] [chunk 9/15] Evaluating [wizard_instruct] prompt: wizard_00064
2025-12-31 15:06:21,361 [INFO] [chunk 9/15] Evaluating [wizard_instruct] prompt: wizard_00065
2025-12-31 15:15:56,572 [INFO] [chunk 9/15] Evaluating [wizard_instruct] prompt: wizard_00066
2025-12-31 15:32:24,187 [INFO] [chunk 9/15] Evaluating [wizard_instruct] prompt: wizard_00067
2025-12-31 15:55:59,272 [INFO] [chunk 9/15] Evaluating [wizard_instruct] prompt: wizard_00068
2025-12-31 16:14:46,825 [INFO] [chunk 9/15] Evaluating [wizard_instruct] prompt: wizard_00069
2025-12-31 16:25:40,948 [INFO] [chunk 9/15] [wizard_instruct] Global Success@OGF>=1 across 238 runs (this chunk): 7.56%

================================================================================
                     Resource Usage on 31/12/2025 16:25:45                      

Job Id: 7316629[9] 
Queue: ADFA
Walltime: 07:23:42  (requested 12:00:00)
Job execution was successful. Exit Status 0. 

--------------------------------------------------------------------------------
|              |             GPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node  GPU ID | Requested   Used   Efficiency | Available   Used              |
| k094    5    |     1       0.74       74%    | 46068 MiB  44.62G             |
--------------------------------------------------------------------------------
|Total         |     1       0.74      74.0%   |                               |
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
|              |             CPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node         | Requested   Used   Efficiency | Requested   Used   Efficiency |
| k094         |     4        1.0      25.0%   |  32.0gb    14.69gb    45.9%   |
--------------------------------------------------------------------------------
