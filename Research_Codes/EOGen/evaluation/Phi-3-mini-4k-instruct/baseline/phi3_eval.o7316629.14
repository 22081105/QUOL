================ HW / GPU INFO ================
Date: Wed Dec 31 13:00:57 AEDT 2025
Host: k096
Job:  7316629[14].<CLUSTER_DOMAIN>  ArrayIndex: 14
GPU 0: NVIDIA L40S (UUID: GPU-33ea0ca2-b627-f60c-f89c-144a4a8982b6)
0, NVIDIA L40S, GPU-33ea0ca2-b627-f60c-f89c-144a4a8982b6, 580.95.05, 46068 MiB
===============================================
2025-12-31 13:01:27,759 [INFO] [chunk 14/15] Loading tokenizer and model: microsoft/Phi-3-mini-4k-instruct
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:12<00:12, 12.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  8.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.36s/it]
2025-12-31 13:01:49,489 [INFO] [chunk 14/15] Model loaded on cuda
2025-12-31 13:01:49,489 [INFO] [chunk 14/15] Context limit C = 4096, max_new_tokens B = 16384
2025-12-31 13:01:49,490 [INFO] [chunk 14/15] No prompts for family 'repeat_style'; skipping.
2025-12-31 13:01:49,496 [INFO] [chunk 14/15] Evaluating [infinite_babble] prompt: infinite_babble_v29
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
This is a friendly reminder - the current text generation call has exceeded the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.
2025-12-31 13:36:47,764 [INFO] [chunk 14/15] Evaluating [infinite_babble] prompt: infinite_babble_v30
2025-12-31 14:15:23,959 [INFO] [chunk 14/15] [infinite_babble] Global Success@OGF>=1 across 68 runs (this chunk): 25.00%
2025-12-31 14:15:23,960 [INFO] [chunk 14/15] Evaluating [random_short] prompt: random_098
2025-12-31 14:43:54,981 [INFO] [chunk 14/15] Evaluating [random_short] prompt: random_099
2025-12-31 15:03:39,744 [INFO] [chunk 14/15] [random_short] Global Success@OGF>=1 across 68 runs (this chunk): 19.12%
2025-12-31 15:03:39,744 [INFO] [chunk 14/15] Loaded 100 Wizard-style prompts from wizardlm.jsonl
2025-12-31 15:03:39,745 [INFO] [chunk 14/15] Evaluating [wizard_instruct] prompt: wizard_00098
2025-12-31 15:10:09,897 [INFO] [chunk 14/15] Evaluating [wizard_instruct] prompt: wizard_00099
2025-12-31 15:15:38,860 [INFO] [chunk 14/15] [wizard_instruct] Global Success@OGF>=1 across 68 runs (this chunk): 1.47%

================================================================================
                     Resource Usage on 31/12/2025 15:15:43                      

Job Id: 7316629[14] 
Queue: ADFA
Walltime: 02:14:43  (requested 12:00:00)
Job execution was successful. Exit Status 0. 

--------------------------------------------------------------------------------
|              |             GPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node  GPU ID | Requested   Used   Efficiency | Available   Used              |
| k096    5    |     1       0.89       89%    | 46068 MiB   8.75G             |
--------------------------------------------------------------------------------
|Total         |     1       0.89      89.0%   |                               |
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
|              |             CPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node         | Requested   Used   Efficiency | Requested   Used   Efficiency |
| k096         |     4       0.99      25.0%   |  32.0gb    14.7gb     45.9%   |
--------------------------------------------------------------------------------
