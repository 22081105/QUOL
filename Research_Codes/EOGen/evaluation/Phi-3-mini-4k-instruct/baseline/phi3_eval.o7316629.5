================ HW / GPU INFO ================
Date: Wed Dec 31 08:25:56 AEDT 2025
Host: k172
Job:  7316629[5].<CLUSTER_DOMAIN>  ArrayIndex: 5
GPU 0: NVIDIA L40S (UUID: GPU-10c64d3c-ac60-a8eb-67a9-faa6aaef3897)
0, NVIDIA L40S, GPU-10c64d3c-ac60-a8eb-67a9-faa6aaef3897, 580.95.05, 46068 MiB
===============================================
2025-12-31 08:26:19,469 [INFO] [chunk 5/15] Loading tokenizer and model: microsoft/Phi-3-mini-4k-instruct
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.43s/it]
2025-12-31 08:26:37,478 [INFO] [chunk 5/15] Model loaded on cuda
2025-12-31 08:26:37,478 [INFO] [chunk 5/15] Context limit C = 4096, max_new_tokens B = 16384
2025-12-31 08:26:37,481 [INFO] [chunk 5/15] Evaluating [repeat_style] prompt: count_v1
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
This is a friendly reminder - the current text generation call has exceeded the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.
2025-12-31 09:26:22,872 [INFO] [chunk 5/15] Evaluating [repeat_style] prompt: count_v2
2025-12-31 09:35:14,129 [INFO] [chunk 5/15] [repeat_style] Global Success@OGF>=1 across 68 runs (this chunk): 25.00%
2025-12-31 09:35:14,129 [INFO] [chunk 5/15] Evaluating [infinite_babble] prompt: infinite_babble_v11
2025-12-31 10:09:01,978 [INFO] [chunk 5/15] Evaluating [infinite_babble] prompt: infinite_babble_v12
2025-12-31 10:53:17,361 [INFO] [chunk 5/15] [infinite_babble] Global Success@OGF>=1 across 68 runs (this chunk): 38.24%
2025-12-31 10:53:17,362 [INFO] [chunk 5/15] Evaluating [random_short] prompt: random_035
2025-12-31 11:13:13,736 [INFO] [chunk 5/15] Evaluating [random_short] prompt: random_036
2025-12-31 11:46:10,301 [INFO] [chunk 5/15] Evaluating [random_short] prompt: random_037
2025-12-31 11:54:37,930 [INFO] [chunk 5/15] Evaluating [random_short] prompt: random_038
2025-12-31 12:06:15,516 [INFO] [chunk 5/15] Evaluating [random_short] prompt: random_039
2025-12-31 12:19:38,432 [INFO] [chunk 5/15] Evaluating [random_short] prompt: random_040
2025-12-31 12:32:33,350 [INFO] [chunk 5/15] Evaluating [random_short] prompt: random_041
2025-12-31 12:49:05,954 [INFO] [chunk 5/15] [random_short] Global Success@OGF>=1 across 238 runs (this chunk): 11.76%
2025-12-31 12:49:05,955 [INFO] [chunk 5/15] Loaded 100 Wizard-style prompts from wizardlm.jsonl
2025-12-31 12:49:05,956 [INFO] [chunk 5/15] Evaluating [wizard_instruct] prompt: wizard_00035
2025-12-31 13:15:28,131 [INFO] [chunk 5/15] Evaluating [wizard_instruct] prompt: wizard_00036
2025-12-31 13:29:27,585 [INFO] [chunk 5/15] Evaluating [wizard_instruct] prompt: wizard_00037
2025-12-31 13:51:10,209 [INFO] [chunk 5/15] Evaluating [wizard_instruct] prompt: wizard_00038
2025-12-31 14:10:43,093 [INFO] [chunk 5/15] Evaluating [wizard_instruct] prompt: wizard_00039
2025-12-31 14:32:49,334 [INFO] [chunk 5/15] Evaluating [wizard_instruct] prompt: wizard_00040
2025-12-31 14:43:28,601 [INFO] [chunk 5/15] Evaluating [wizard_instruct] prompt: wizard_00041
2025-12-31 14:52:59,622 [INFO] [chunk 5/15] [wizard_instruct] Global Success@OGF>=1 across 238 runs (this chunk): 10.08%

================================================================================
                     Resource Usage on 31/12/2025 14:53:03                      

Job Id: 7316629[5] 
Queue: ADFA
Walltime: 06:27:05  (requested 12:00:00)
Job execution was successful. Exit Status 0. 

--------------------------------------------------------------------------------
|              |             GPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node  GPU ID | Requested   Used   Efficiency | Available   Used              |
| k172    2    |     1       0.92       92%    | 46068 MiB   8.75G             |
--------------------------------------------------------------------------------
|Total         |     1       0.92      92.0%   |                               |
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
|              |             CPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node         | Requested   Used   Efficiency | Requested   Used   Efficiency |
| k172         |     4        1.0      25.0%   |  32.0gb    10.29gb    32.2%   |
--------------------------------------------------------------------------------
