================ HW / GPU INFO ================
Date: Wed Dec 31 16:31:37 AEDT 2025
Host: k094
Job:  7316805[0].<CLUSTER_DOMAIN>  ArrayIndex: 0
GPU 0: NVIDIA L40S (UUID: GPU-521a81fc-da81-ca47-beeb-1055b1101011)
0, NVIDIA L40S, GPU-521a81fc-da81-ca47-beeb-1055b1101011, 580.95.05, 46068 MiB
===============================================
2025-12-31 16:32:00,795 [INFO] [chunk 0/15] Loading tokenizer and model: meta-llama/Llama-2-7b-hf
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:23<00:23, 23.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:31<00:00, 14.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:31<00:00, 15.94s/it]
2025-12-31 16:32:35,742 [INFO] [chunk 0/15] Model loaded on cuda
2025-12-31 16:32:35,742 [INFO] [chunk 0/15] Context limit C = 4096, max_new_tokens B = 16384
2025-12-31 16:32:35,748 [INFO] [chunk 0/15] Evaluating [repeat_style] prompt: repeat_v1
This is a friendly reminder - the current text generation call has exceeded the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.
2025-12-31 16:42:30,709 [INFO] [chunk 0/15] Evaluating [repeat_style] prompt: repeat_v2
2025-12-31 16:56:50,886 [INFO] [chunk 0/15] [repeat_style] Global Success@OGF>=1 across 68 runs (this chunk): 7.35%
2025-12-31 16:56:50,886 [INFO] [chunk 0/15] Evaluating [infinite_babble] prompt: infinite_babble_v01
2025-12-31 17:26:31,837 [INFO] [chunk 0/15] Evaluating [infinite_babble] prompt: infinite_babble_v02
2025-12-31 18:09:12,249 [INFO] [chunk 0/15] [infinite_babble] Global Success@OGF>=1 across 68 runs (this chunk): 17.65%
2025-12-31 18:09:12,250 [INFO] [chunk 0/15] Evaluating [random_short] prompt: random_000
2025-12-31 18:19:07,608 [INFO] [chunk 0/15] Evaluating [random_short] prompt: random_001
2025-12-31 18:33:04,143 [INFO] [chunk 0/15] Evaluating [random_short] prompt: random_002
2025-12-31 18:57:45,376 [INFO] [chunk 0/15] Evaluating [random_short] prompt: random_003
2025-12-31 19:25:45,598 [INFO] [chunk 0/15] Evaluating [random_short] prompt: random_004
2025-12-31 20:23:21,516 [INFO] [chunk 0/15] Evaluating [random_short] prompt: random_005
2025-12-31 20:32:33,022 [INFO] [chunk 0/15] Evaluating [random_short] prompt: random_006
2025-12-31 20:55:22,192 [INFO] [chunk 0/15] [random_short] Global Success@OGF>=1 across 238 runs (this chunk): 11.76%
2025-12-31 20:55:22,204 [INFO] [chunk 0/15] Loaded 100 Wizard-style prompts from wizardlm.jsonl
2025-12-31 20:55:22,205 [INFO] [chunk 0/15] Evaluating [wizard_instruct] prompt: wizard_00000
2025-12-31 21:04:15,454 [INFO] [chunk 0/15] Evaluating [wizard_instruct] prompt: wizard_00001
2025-12-31 21:13:40,492 [INFO] [chunk 0/15] Evaluating [wizard_instruct] prompt: wizard_00002
2025-12-31 21:25:25,904 [INFO] [chunk 0/15] Evaluating [wizard_instruct] prompt: wizard_00003
2025-12-31 21:36:22,879 [INFO] [chunk 0/15] Evaluating [wizard_instruct] prompt: wizard_00004
2025-12-31 21:49:54,398 [INFO] [chunk 0/15] Evaluating [wizard_instruct] prompt: wizard_00005
2025-12-31 22:05:49,168 [INFO] [chunk 0/15] Evaluating [wizard_instruct] prompt: wizard_00006
2025-12-31 22:13:16,186 [INFO] [chunk 0/15] [wizard_instruct] Global Success@OGF>=1 across 238 runs (this chunk): 5.46%

================================================================================
                     Resource Usage on 31/12/2025 22:13:19                      

Job Id: 7316805[0] 
Queue: ADFA
Walltime: 05:41:40  (requested 12:00:00)
Job execution was successful. Exit Status 0. 

--------------------------------------------------------------------------------
|              |             GPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node  GPU ID | Requested   Used   Efficiency | Available   Used              |
| k094    5    |     1       0.97       97%    | 46068 MiB  44.63G             |
--------------------------------------------------------------------------------
|Total         |     1       0.97      97.0%   |                               |
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
|              |             CPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node         | Requested   Used   Efficiency | Requested   Used   Efficiency |
| k094         |     4       0.99      25.0%   |  32.0gb    25.58gb    79.9%   |
--------------------------------------------------------------------------------
