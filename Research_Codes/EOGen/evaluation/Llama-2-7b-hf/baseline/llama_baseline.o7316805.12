================ HW / GPU INFO ================
Date: Wed Dec 31 19:12:46 AEDT 2025
Host: k173
Job:  7316805[12].<CLUSTER_DOMAIN>  ArrayIndex: 12
GPU 0: NVIDIA L40S (UUID: GPU-d9f96a87-6436-3a41-e0ea-9b7640044abd)
0, NVIDIA L40S, GPU-d9f96a87-6436-3a41-e0ea-9b7640044abd, 580.95.05, 46068 MiB
===============================================
2025-12-31 19:13:15,257 [INFO] [chunk 12/15] Loading tokenizer and model: meta-llama/Llama-2-7b-hf
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:23<00:23, 23.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:32<00:00, 14.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:32<00:00, 16.16s/it]
2025-12-31 19:13:51,355 [INFO] [chunk 12/15] Model loaded on cuda
2025-12-31 19:13:51,356 [INFO] [chunk 12/15] Context limit C = 4096, max_new_tokens B = 16384
2025-12-31 19:13:51,360 [INFO] [chunk 12/15] Evaluating [repeat_style] prompt: code_v5
This is a friendly reminder - the current text generation call has exceeded the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.
2025-12-31 19:34:47,164 [INFO] [chunk 12/15] [repeat_style] Global Success@OGF>=1 across 34 runs (this chunk): 17.65%
2025-12-31 19:34:47,164 [INFO] [chunk 12/15] Evaluating [infinite_babble] prompt: infinite_babble_v25
2025-12-31 19:54:35,439 [INFO] [chunk 12/15] Evaluating [infinite_babble] prompt: infinite_babble_v26
2025-12-31 20:15:54,474 [INFO] [chunk 12/15] [infinite_babble] Global Success@OGF>=1 across 68 runs (this chunk): 11.76%
2025-12-31 20:15:54,475 [INFO] [chunk 12/15] Evaluating [random_short] prompt: random_084
2025-12-31 20:45:27,975 [INFO] [chunk 12/15] Evaluating [random_short] prompt: random_085
2025-12-31 21:25:18,148 [INFO] [chunk 12/15] Evaluating [random_short] prompt: random_086
2025-12-31 21:34:47,603 [INFO] [chunk 12/15] Evaluating [random_short] prompt: random_087
2025-12-31 21:59:11,538 [INFO] [chunk 12/15] Evaluating [random_short] prompt: random_088
2025-12-31 22:21:39,958 [INFO] [chunk 12/15] Evaluating [random_short] prompt: random_089
2025-12-31 22:45:55,475 [INFO] [chunk 12/15] Evaluating [random_short] prompt: random_090
2025-12-31 22:50:58,678 [INFO] [chunk 12/15] [random_short] Global Success@OGF>=1 across 238 runs (this chunk): 11.76%
2025-12-31 22:50:58,679 [INFO] [chunk 12/15] Loaded 100 Wizard-style prompts from wizardlm.jsonl
2025-12-31 22:50:58,680 [INFO] [chunk 12/15] Evaluating [wizard_instruct] prompt: wizard_00084
2025-12-31 22:56:29,647 [INFO] [chunk 12/15] Evaluating [wizard_instruct] prompt: wizard_00085
2025-12-31 23:06:17,266 [INFO] [chunk 12/15] Evaluating [wizard_instruct] prompt: wizard_00086
2025-12-31 23:12:23,002 [INFO] [chunk 12/15] Evaluating [wizard_instruct] prompt: wizard_00087
2025-12-31 23:21:22,552 [INFO] [chunk 12/15] Evaluating [wizard_instruct] prompt: wizard_00088
2025-12-31 23:47:10,939 [INFO] [chunk 12/15] Evaluating [wizard_instruct] prompt: wizard_00089
2025-12-31 23:57:19,071 [INFO] [chunk 12/15] Evaluating [wizard_instruct] prompt: wizard_00090
2026-01-01 00:23:48,033 [INFO] [chunk 12/15] [wizard_instruct] Global Success@OGF>=1 across 238 runs (this chunk): 2.94%

================================================================================
                     Resource Usage on 01/01/2026 00:23:51                      

Job Id: 7316805[12] 
Queue: ADFA
Walltime: 05:11:02  (requested 12:00:00)
Job execution was successful. Exit Status 0. 

--------------------------------------------------------------------------------
|              |             GPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node  GPU ID | Requested   Used   Efficiency | Available   Used              |
| k173    2    |     1       0.97       97%    | 46068 MiB  44.62G             |
--------------------------------------------------------------------------------
|Total         |     1       0.97      97.0%   |                               |
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
|              |             CPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node         | Requested   Used   Efficiency | Requested   Used   Efficiency |
| k173         |     4        1.0      25.0%   |  32.0gb    25.58gb    79.9%   |
--------------------------------------------------------------------------------
