================ HW / GPU INFO ================
Date: Wed Dec 31 21:13:58 AEDT 2025
Host: k172
Job:  7316805[13].<CLUSTER_DOMAIN>  ArrayIndex: 13
GPU 0: NVIDIA L40S (UUID: GPU-b706d410-5a09-a8e8-715c-f4197707c2e7)
0, NVIDIA L40S, GPU-b706d410-5a09-a8e8-715c-f4197707c2e7, 580.95.05, 46068 MiB
===============================================
2025-12-31 21:14:27,301 [INFO] [chunk 13/15] Loading tokenizer and model: meta-llama/Llama-2-7b-hf
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:24<00:24, 24.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:33<00:00, 15.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:33<00:00, 16.90s/it]
2025-12-31 21:15:04,566 [INFO] [chunk 13/15] Model loaded on cuda
2025-12-31 21:15:04,566 [INFO] [chunk 13/15] Context limit C = 4096, max_new_tokens B = 16384
2025-12-31 21:15:04,566 [INFO] [chunk 13/15] No prompts for family 'repeat_style'; skipping.
2025-12-31 21:15:04,570 [INFO] [chunk 13/15] Evaluating [infinite_babble] prompt: infinite_babble_v27
2025-12-31 21:23:26,128 [INFO] [chunk 13/15] Evaluating [infinite_babble] prompt: infinite_babble_v28
This is a friendly reminder - the current text generation call has exceeded the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.
2025-12-31 21:51:08,423 [INFO] [chunk 13/15] [infinite_babble] Global Success@OGF>=1 across 68 runs (this chunk): 7.35%
2025-12-31 21:51:08,424 [INFO] [chunk 13/15] Evaluating [random_short] prompt: random_091
2025-12-31 22:05:08,285 [INFO] [chunk 13/15] Evaluating [random_short] prompt: random_092
2025-12-31 22:37:57,685 [INFO] [chunk 13/15] Evaluating [random_short] prompt: random_093
2025-12-31 23:10:54,852 [INFO] [chunk 13/15] Evaluating [random_short] prompt: random_094
2025-12-31 23:40:50,740 [INFO] [chunk 13/15] Evaluating [random_short] prompt: random_095
2026-01-01 00:01:44,662 [INFO] [chunk 13/15] Evaluating [random_short] prompt: random_096
2026-01-01 00:41:47,559 [INFO] [chunk 13/15] Evaluating [random_short] prompt: random_097
2026-01-01 01:25:32,288 [INFO] [chunk 13/15] [random_short] Global Success@OGF>=1 across 238 runs (this chunk): 16.39%
2026-01-01 01:25:32,299 [INFO] [chunk 13/15] Loaded 100 Wizard-style prompts from wizardlm.jsonl
2026-01-01 01:25:32,300 [INFO] [chunk 13/15] Evaluating [wizard_instruct] prompt: wizard_00091
2026-01-01 01:35:11,677 [INFO] [chunk 13/15] Evaluating [wizard_instruct] prompt: wizard_00092
2026-01-01 01:42:27,193 [INFO] [chunk 13/15] Evaluating [wizard_instruct] prompt: wizard_00093
2026-01-01 01:50:30,121 [INFO] [chunk 13/15] Evaluating [wizard_instruct] prompt: wizard_00094
2026-01-01 01:56:13,926 [INFO] [chunk 13/15] Evaluating [wizard_instruct] prompt: wizard_00095
2026-01-01 02:12:49,488 [INFO] [chunk 13/15] Evaluating [wizard_instruct] prompt: wizard_00096
2026-01-01 02:29:52,043 [INFO] [chunk 13/15] Evaluating [wizard_instruct] prompt: wizard_00097
2026-01-01 02:38:43,742 [INFO] [chunk 13/15] [wizard_instruct] Global Success@OGF>=1 across 238 runs (this chunk): 1.68%

================================================================================
                     Resource Usage on 01/01/2026 02:38:47                      

Job Id: 7316805[13] 
Queue: ADFA
Walltime: 05:24:47  (requested 12:00:00)
Job execution was successful. Exit Status 0. 

--------------------------------------------------------------------------------
|              |             GPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node  GPU ID | Requested   Used   Efficiency | Available   Used              |
| k172    3    |     1       0.97       97%    | 46068 MiB  44.62G             |
--------------------------------------------------------------------------------
|Total         |     1       0.97      97.0%   |                               |
--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
|              |             CPUs              |            Memory             |
--------------------------------------------------------------------------------
| Node         | Requested   Used   Efficiency | Requested   Used   Efficiency |
| k172         |     4        1.0      25.0%   |  32.0gb    25.58gb    79.9%   |
--------------------------------------------------------------------------------
